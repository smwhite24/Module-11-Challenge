# Mars Web Scraping and Data Analysis Project

## Overview
This project involves web scraping and data analysis tasks that showcase the skills of automated browsing and HTML parsing using Python libraries such as Splinter and BeautifulSoup. The project focuses on collecting, organizing, analyzing, and visualizing data extracted from two different sources on the web. These tasks are completed in two parts:

1. Scraping Mars news articles: Extracting titles and preview texts from news articles.
2. Scraping Mars weather data: Extracting and analyzing weather-related data from an HTML table.

## Project Deliverables
This project has two main deliverables:

### Deliverable 1: Scrape Titles and Preview Text from Mars News Articles
You will scrape the NASA Mars news website to collect the latest articles, including the titles and their corresponding preview texts. This process involves:
- Identifying the HTML elements of interest (e.g., titles and preview text).
- Writing a Python script to automate the extraction of the news data.
- Storing the scraped data for further analysis.

### Deliverable 2: Scrape and Analyze Mars Weather Data
You will scrape Mars weather data, which is stored in a table format. After scraping the table, you will:
- Parse the table to collect the relevant weather information.
- Perform basic analysis on the data (e.g., summarizing, cleaning, or visualizing trends).
- Store and present the results for review.

## Tools and Libraries Used
- **Python**: Core programming language used for automation and data analysis.
- **Splinter**: A browser automation tool used for navigating and interacting with web pages.
- **BeautifulSoup**: A Python library used for parsing HTML and XML documents to extract data.
- **Pandas**: A data manipulation and analysis library for organizing, cleaning, and analyzing the scraped data.
- **Matplotlib/Seaborn**: Data visualization libraries for presenting insights from the weather data.

## Instructions to Run the Project
1. Clone this repository to your local machine.
  
2. Run the script for **Deliverable 1** to scrape the Mars news articles by executing:
   ```bash
   part_1_mars_news.ipynb
   ```
3. Run the script for **Deliverable 2** to scrape and analyze the Mars weather data by executing:
   ```bash
   part_2_mars_weather.ipynb
   ```
4. The results of PART 2 scraping tasks will be saved to `.csv` file for further review and analysis.

## File Structure
```bash
├── README.md                # Project overview and instructions (this file)
├── part_1_mars_news.ipynb       # Script to scrape Mars news articles
├── part_2_mars_weather.ipynb    # Script to scrape and analyze Mars weather data
├── requirements.txt          # List of required Python packages
└── data                      # Directory containing scraped data (CSV files)
```

## Contributing
Utilized Xpert learning assistant and google to troubleshot code.
class work and activities to assist with code


---
